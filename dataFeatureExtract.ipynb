{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Process From .MAT to .NPY (NumPy)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "print(\"scipy version: \", scipy.__version__)\n",
    "print(\"numpy version: \", np.__version__)\n",
    "print(\"pandas version: \", pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C:\\Users\\kevin\\Downloads\\workingDirectory\n",
    "wkdirPath = 'C:\\\\Users\\\\kevin\\\\Downloads\\\\workingDirectory\\\\' # change this to your working directory\n",
    "dataRawFolder = 'ds002723\\\\'\n",
    "dataPreprocessedFolder = 'preprocessed\\\\'\n",
    "dataSegmentedFolder = 'segmented\\\\'\n",
    "datasetFolder = 'dataset\\\\'\n",
    "\n",
    "inputFolder = 'X\\\\'\n",
    "outputFolder = 'y\\\\'\n",
    "\n",
    "\n",
    "inputSegmentedPath = wkdirPath + dataSegmentedFolder + inputFolder\n",
    "outputSegmentedPath = wkdirPath + dataSegmentedFolder + outputFolder\n",
    "\n",
    "datasetPath = wkdirPath + datasetFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputMatFileList = [file for file in os.listdir(inputSegmentedPath) if file.lower().endswith(\".mat\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempStorage = None\n",
    "matFileList = [file for file in os.listdir(inputSegmentedPath) if file.lower().endswith(\".mat\")]\n",
    "for matFile in matFileList:\n",
    "    mat = scipy.io.loadmat(inputSegmentedPath + matFile)\n",
    "    \n",
    "    dataTemp = mat['EEGData'].transpose(2,0,1)\n",
    "\n",
    "    if tempStorage is None:\n",
    "        tempStorage = dataTemp\n",
    "    else:\n",
    "        tempStorage = np.append(tempStorage, dataTemp, axis=0)\n",
    "\n",
    "assert tempStorage is not None, 'Data is empty'\n",
    "data['x'] = tempStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['x'].shape)\n",
    "print(data['x'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputMatFileList = [file for file in os.listdir(outputSegmentedPath) if file.lower().endswith(\".mat\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempStorage = None\n",
    "matFileList = [file for file in os.listdir(outputSegmentedPath) if file.lower().endswith(\".mat\")]\n",
    "for matFile in matFileList:\n",
    "    mat = scipy.io.loadmat(outputSegmentedPath + matFile)\n",
    "    \n",
    "    dataTemp = mat['EEGEventType'].transpose(1,0)\n",
    "\n",
    "    if tempStorage is None:\n",
    "        tempStorage = dataTemp\n",
    "    else:\n",
    "        tempStorage = np.append(tempStorage, dataTemp, axis=0)\n",
    "\n",
    "assert tempStorage is not None, 'Data is empty'\n",
    "data['y'] = tempStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['y'].shape)\n",
    "print(data['y'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(datasetPath + 'X.npy', data['x'])\n",
    "np.save(datasetPath + 'y.npy', data['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Feature Extract**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne_features as mnef \n",
    "import mne\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"mne_features version: \", mnef.__version__)\n",
    "print(\"mne version: \", mne.__version__)\n",
    "print(\"scikit-learn version: \", sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = pd.read_csv(wkdirPath + dataSegmentedFolder + 'channelData.csv')\n",
    "channels = tuple(channels.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(datasetPath + 'X.npy')\n",
    "y = np.load(datasetPath + 'y.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Experimental Feature Extraction (skip this)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preparation for Experiment (skip this)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_test_pd = pd.DataFrame(X_test, columns=channels)\n",
    "y_train_pd = pd.DataFrame(y_train, columns=channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_uni_opt = mnef.feature_extraction.get_univariate_func_names()\n",
    "function_bi_opt = mnef.feature_extraction.get_bivariate_func_names()\n",
    "print(function_uni_opt)\n",
    "print(function_bi_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = mnef.feature_extraction.FeatureExtractor(sfreq=1000, selected_funcs='all', selected_funcs_params=None, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "n_epochs, n_channels, n_times = X_train.shape\n",
    "selected_funcs=['quantile', 'rms', 'std', 'zero_crossings', 'ptp_amp', 'variance']\n",
    "\n",
    "def extractFeatures(X_data:np.ndarray, selected_funcs:tuple, ch_names:tuple):\n",
    "    print(selected_funcs)\n",
    "    print(ch_names)\n",
    "    n_jobs=1\n",
    "    return mnef.feature_extraction.extract_features(X_data, sfreq=1000, selected_funcs=selected_funcs, n_jobs=n_jobs, ch_names=ch_names, return_as_df=True)\n",
    "\n",
    "X_train_fe_df = extractFeatures(X_train, selected_funcs, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_to_id = dict((channels[i],i) for i in range(len(channels)))\n",
    "id_to_channels = dict((i,channels[i]) for i in range(len(channels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rng = np.random.RandomState(42)\n",
    "n_epochs, n_channels, n_times = X_train.shape\n",
    "\n",
    "selected_funcs=['quantile', 'rms', 'std', 'zero_crossings', 'ptp_amp', 'variance']\n",
    "funcs_params=None\n",
    "n_jobs=1\n",
    "ch_names= channels\n",
    "\n",
    "# fe = mnef.feature_extraction.FeatureExtractor(sfreq=1000, selected_funcs=selected_funcs, n_jobs=n_jobs)\n",
    "# X_train_fe = fe.fit_transform(X_train)\n",
    "\n",
    "X_train_fe_frontal_df = extractFeatures(X_train[:,:14,:], selected_funcs=selected_funcs, ch_names=ch_names[:14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_fe_df.shape)\n",
    "fe_index_label = tuple(X_train_fe_df.keys())\n",
    "print(len(fe_index_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_fe_df_14.shape)\n",
    "fe_frontal_index_label = tuple(X_train_fe_df_14.keys())\n",
    "print(len(fe_frontal_index_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (extra) Features -> Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = tuple(i+'-'+j for i,j in list(X_train_fe_df_14.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "ploy = PolynomialFeatures(degree=2, interaction_only=False)\n",
    "\n",
    "\n",
    "X_train_poly = ploy.fit_transform(X_train_fe_df_14)\n",
    "# Restructure the data into dataframe with column names\n",
    "X_train_poly = pd.DataFrame(X_train_poly, columns=ploy.get_feature_names_out(keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_label = dict((i,fe_index_label[i]) for i in range(len(fe_index_label)))\n",
    "label_to_id = dict((fe_index_label[i],i) for i in range(len(fe_index_label)))\n",
    "print(len(label_to_id)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_poly.shape)\n",
    "fe_poly_index_label = tuple(X_train_poly.keys())\n",
    "print(len(fe_poly_index_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Experiment for Feature Selection (skip this)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline   \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import RidgeClassifier, SGDClassifier, LogisticRegression, PassiveAggressiveClassifier, Perceptron, BayesianRidge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Experiment & Notes (skip this)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'quantile', 'rms', 'std', 'zero_crossings', 'ptp_amp', 'teager_kaiser_energy', 'wavelet_coef_energy', 'variance', 'hjorth_mobility_spect'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory Alloc Error: 'svd_fisher_info', 'svd_entropy'\n",
    "Index Error: 'spect_edge_freq'\n",
    "\n",
    "- wavelet_coef_energy (160 dari n_channels * 6)\n",
    "12\tFP2_0\t0.000772\n",
    "55\tFC5_1\t0.000379\n",
    "0\tFP1_0\t0.000314\n",
    "92\tC3_2\t0.000124\n",
    "56\tFC5_2\t0.000105\n",
    "28\tF3_4\t0.000102\n",
    "174\tP8_0\t0.000096\n",
    "163\tPz_1\t0.000092\n",
    "121\tCP5_1\t0.000089\n",
    "19\tF7_1\t0.000084\n",
    "\n",
    "- variance\n",
    "0\tFP1\t0.000186\n",
    "1\tFPz\t0.000140\n",
    "\n",
    "- ptp_amp\n",
    "1\tFPz\t0.000879\n",
    "0\tFP1\t0.000366\n",
    "8\tFT9\t0.000062\n",
    "- quantile\n",
    "0\tFP1\t0.027407\n",
    "- std\n",
    "0\tFP1\t0.008499\n",
    "1\tFPz\t0.006849\n",
    "- rms\n",
    "1\tFPz\t0.009563\n",
    "0\tFP1\t0.00628\n",
    "\n",
    "- teager_kaiser_energy (93 dari n_channels * 14)\n",
    "42\tF7_0_mean\t0.001042\n",
    "9\tFP1_4_std\t0.000675\n",
    "367\tP3_1_std\t0.000628\n",
    "177\tFC6_4_std\t0.000591\n",
    "353\tP7_1_std\t0.000580\n",
    "70\tFz_0_mean\t0.000564\n",
    "170\tFC6_1_mean\t0.000533\n",
    "227\tCz_1_std\t0.000458\n",
    "336\tTP10_0_mean\t0.000454\n",
    "199\tT7_1_std\t0.000399\n",
    "422\tO1_1_mean\t0.000363\n",
    "189\tFT10_3_std\t0.000314\n",
    "339\tTP10_1_std\t0.000288\n",
    "327\tCP6_2_std\t0.000275\n",
    "269\tTP9_1_std\t0.000275\n",
    "259\tT8_3_std\t0.000260\n",
    "351\tP7_0_std\t0.000258\n",
    "197\tT7_0_std\t0.000226\n",
    "73\tFz_1_std\t0.000224\n",
    "77\tFz_3_std\t0.00020\n",
    "\n",
    "\n",
    "- zero_crossings\n",
    "9\tFC5\t0.000791\n",
    "5\tFz\t0.000673\n",
    "28\tP4\t0.000409\n",
    "2\tFP2\t0.000351\n",
    "6\tF4\t0.000328\n",
    "1\tFPz\t0.000254\n",
    "29\tP8\t0.000240\n",
    "12\tFC6\t0.000227\n",
    "16\tCz\t0.000201\n",
    "0\tFP1\t0.000111\n",
    "7\tF8\t0.000103\n",
    "18\tT8\t0.000077\n",
    "13\tFT10\t0.000038\n",
    "11\tFC2\t0.000027\n",
    "14\tT7\t0.000025\n",
    "20\tCP5\t0.000021\n",
    "\n",
    "\n",
    "- hjorth_complexity_spect\n",
    "15\tC3\t3.968751e-08\n",
    "4\tF3\t2.224511e-08\n",
    "27\tPz\t1.177913e-08\n",
    "30\tO1\t9.042004e-09\n",
    "20\tCP5\t8.961986e-09\n",
    "26\tP3\t7.410903e-09\n",
    "21\tCP1\t5.200852e-09\n",
    "25\tP7\t4.460091e-09\n",
    "14\tT7\t2.510036e-09\n",
    "5\tFz\t1.619238e-09\n",
    "31\tO2\t1.173183e-09\n",
    "10\tFC1\t1.139675e-09\n",
    "29\tP8\t8.968749e-10\n",
    "16\tCz\t8.757678e-10\n",
    "0\tFP1\t8.630175e-10\n",
    "28\tP4\t7.337888e-10\n",
    "22\tCP2\t7.156483e-10\n",
    "19\tTP9\t5.454429e-10\n",
    "12\tFC6\t3.172492e-10\n",
    "2\tFP2\t2.413746e-10\n",
    "7\tF8\t2.129390e-10\n",
    "1\tFPz\t1.723450e-10\n",
    "18\tT8\t1.599379e-10\n",
    "24\tTP10\t1.052916e-10\n",
    "6\tF4\t9.623960e-11\n",
    "23\tCP6\t8.376070e-11\n",
    "11\tFC2\t7.995312e-11\n",
    "9\tFC5\t5.912040e-11\n",
    "17\tC4\t4.242408e-11\n",
    "13\tFT10\t2.149638e-11\n",
    "8\tFT9\t1.418549e-11\n",
    "3\tF7\t5.620082e-12\n",
    "\n",
    "- hjorth_mobility_spect\n",
    "15\tC3\t2.228330e-04\n",
    "4\tF3\t1.145059e-04\n",
    "20\tCP5\t7.796345e-05\n",
    "30\tO1\t5.695755e-05\n",
    "27\tPz\t5.550135e-05\n",
    "9\tFC5\t2.906413e-05\n",
    "14\tT7\t2.347822e-05\n",
    "5\tFz\t1.552919e-05\n",
    "10\tFC1\t1.094639e-05\n",
    "31\tO2\t7.006432e-06\n",
    "0\tFP1\t5.661286e-06\n",
    "29\tP8\t5.292250e-06\n",
    "22\tCP2\t5.092633e-06\n",
    "16\tCz\t4.707477e-06\n",
    "28\tP4\t4.146197e-06\n",
    "12\tFC6\t3.509663e-06\n",
    "1\tFPz\t3.065779e-06\n",
    "19\tTP9\t2.943010e-06\n",
    "24\tTP10\t2.640253e-06\n",
    "2\tFP2\t1.993789e-06\n",
    "7\tF8\t1.704866e-06\n",
    "3\tF7\t1.626791e-06\n",
    "18\tT8\t1.484777e-06\n",
    "6\tF4\t1.427815e-06\n",
    "8\tFT9\t4.988272e-07\n",
    "23\tCP6\t4.035867e-07\n",
    "13\tFT10\t1.591099e-07\n",
    "11\tFC2\t1.218014e-07\n",
    "17\tC4\t2.629278e-08\n",
    "\n",
    "- kurtosis Nil\n",
    "- hjorth_complexity Nil\n",
    "- katz_fd Nil\n",
    "- skewness Nil\n",
    "- spect_entropy Nil\n",
    "- spect_slope Nil\n",
    "- pow_freq_bands Nil\n",
    "- line_length Nil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "                     ('model',Lasso())\n",
    "])\n",
    "search = GridSearchCV(pipeline,\n",
    "                      {'model__alpha':np.arange(0.1,10,0.1)},\n",
    "                      cv = 5, scoring=\"neg_mean_squared_error\",verbose=1\n",
    "                      )\n",
    "search.fit(X_train_poly,y_train)\n",
    "search.best_params_\n",
    "coefficients = search.best_estimator_.named_steps['model'].coef_\n",
    "importance = np.abs(coefficients)\n",
    "\n",
    "feature_score_basic = pd.DataFrame({'feature':list(X_train_poly.keys()),'importance':importance})\n",
    "feature_score_basic_sorted = feature_score_basic.sort_values(by='importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitFreqBandFeatureScore(feature_score_basic, n_band=6):\n",
    "    feature_score_basic_sorted_list = [0,]*n_band\n",
    "    for i in range (0, n_band):\n",
    "        feature_score_basic_sorted_list[i] = feature_score_basic[i::n_band].sort_values(by='importance',ascending=False)\n",
    "    return feature_score_basic_sorted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeaturePerformance(X_data:pd.DataFrame, y):\n",
    "    pipeline = Pipeline([\n",
    "                         ('model',Lasso())\n",
    "    ])\n",
    "    search = GridSearchCV(pipeline,\n",
    "                          {'model__alpha':np.arange(0.1,10,0.1)},\n",
    "                          cv = 5, scoring=\"neg_mean_squared_error\",verbose=-1\n",
    "                          )\n",
    "    search.fit(X_data ,y)\n",
    "    search.best_params_\n",
    "    coefficients = search.best_estimator_.named_steps['model'].coef_\n",
    "    importance = np.abs(coefficients)\n",
    "\n",
    "    \n",
    "    feature_score_basic = pd.DataFrame({'feature':list(X_data.keys()),'importance':importance})\n",
    "    feature_score_basic_sorted = feature_score_basic.sort_values(by='importance',ascending=False)\n",
    "\n",
    "    return feature_score_basic, feature_score_basic_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fe_df_score, X_train_fe_df_score_sorted = getFeaturePerformance(X_train_fe_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_score_basic = pd.DataFrame({'feature':list(X_data_to_experiment.keys()),'importance':importance})\n",
    "# feature_score_basic_sorted = feature_score_basic.sort_values(by='importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_score_basic_sorted.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Feature Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures(X_data:np.ndarray, selected_funcs:tuple, ch_names:tuple):\n",
    "    print(selected_funcs)\n",
    "    print(ch_names)\n",
    "    n_jobs=1\n",
    "    return mnef.feature_extraction.extract_features(X_data, sfreq=1000, selected_funcs=selected_funcs, n_jobs=n_jobs, ch_names=ch_names, return_as_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_funcs = ['quantile', 'rms', 'std', 'zero_crossings', 'ptp_amp', 'variance']\n",
    "X_fe_df = extractFeatures(X, selected_funcs, ch_names=channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fe_df.to_csv(datasetPath+'X_fe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Format Y data**\n",
    "Original is 1-9\n",
    "Modified (2):\n",
    "- 0-8 (y_9)\n",
    "- 0-4 (y_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame(y, columns=['label'])\n",
    "y_df['label'] = y_df['label'].apply(lambda x: x-1)\n",
    "print(y_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df.to_csv(datasetPath+'y_9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if y is 1, 2, 4, 5, then change to 1\n",
    "y_df['label'] = y_df['label'].apply(lambda x: 0 if x in [0,1,3,4] else 1 if x in [2,5] else 2 if x in [6,7] else 3)\n",
    "print(y_df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df.to_csv(datasetPath+'y_4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8155937/#sec2-sensors-21-03414"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
