{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "wkdirPath = 'C:\\\\Users\\\\kevin\\\\Downloads\\\\workingDirectory\\\\' # TODO: Input the working directory path here\n",
    "datasetFolder = 'dataset\\\\'\n",
    "modelFolder = 'model\\\\'\n",
    "metricFolder = 'metric\\\\'\n",
    "\n",
    "datasetPath = wkdirPath + datasetFolder\n",
    "modelPath = wkdirPath + modelFolder\n",
    "metricPath = wkdirPath + metricFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = pd.read_csv(datasetPath + \"X_fe.csv\", header=[0, 1], index_col=0)\n",
    "y_data = pd.read_csv(datasetPath + \"y_4.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0      0\n",
       "1      1\n",
       "2      1\n",
       "3      0\n",
       "4      0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">quantile</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">variance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>FP1</th>\n",
       "      <th>FPz</th>\n",
       "      <th>FP2</th>\n",
       "      <th>F7</th>\n",
       "      <th>F3</th>\n",
       "      <th>Fz</th>\n",
       "      <th>F4</th>\n",
       "      <th>F8</th>\n",
       "      <th>FT9</th>\n",
       "      <th>FC5</th>\n",
       "      <th>...</th>\n",
       "      <th>CP2</th>\n",
       "      <th>CP6</th>\n",
       "      <th>TP10</th>\n",
       "      <th>P7</th>\n",
       "      <th>P3</th>\n",
       "      <th>Pz</th>\n",
       "      <th>P4</th>\n",
       "      <th>P8</th>\n",
       "      <th>O1</th>\n",
       "      <th>O2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.275757</td>\n",
       "      <td>3.171221</td>\n",
       "      <td>6.266855</td>\n",
       "      <td>3.505204</td>\n",
       "      <td>1.761071</td>\n",
       "      <td>3.587153</td>\n",
       "      <td>6.038462</td>\n",
       "      <td>6.392021</td>\n",
       "      <td>4.244585</td>\n",
       "      <td>1.845967</td>\n",
       "      <td>...</td>\n",
       "      <td>68.961700</td>\n",
       "      <td>129.270645</td>\n",
       "      <td>116.701103</td>\n",
       "      <td>68.938408</td>\n",
       "      <td>61.535503</td>\n",
       "      <td>71.211472</td>\n",
       "      <td>90.592781</td>\n",
       "      <td>152.309875</td>\n",
       "      <td>97.097801</td>\n",
       "      <td>130.508011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.482556</td>\n",
       "      <td>4.307556</td>\n",
       "      <td>6.733288</td>\n",
       "      <td>3.605462</td>\n",
       "      <td>2.020469</td>\n",
       "      <td>3.719703</td>\n",
       "      <td>6.900743</td>\n",
       "      <td>6.842275</td>\n",
       "      <td>4.416522</td>\n",
       "      <td>1.803723</td>\n",
       "      <td>...</td>\n",
       "      <td>86.855766</td>\n",
       "      <td>151.384186</td>\n",
       "      <td>133.853088</td>\n",
       "      <td>77.523170</td>\n",
       "      <td>70.528954</td>\n",
       "      <td>84.750725</td>\n",
       "      <td>108.770752</td>\n",
       "      <td>167.561554</td>\n",
       "      <td>114.627052</td>\n",
       "      <td>143.692932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.936589</td>\n",
       "      <td>8.235714</td>\n",
       "      <td>7.147687</td>\n",
       "      <td>6.368727</td>\n",
       "      <td>2.023022</td>\n",
       "      <td>5.579708</td>\n",
       "      <td>8.134004</td>\n",
       "      <td>9.014104</td>\n",
       "      <td>5.933595</td>\n",
       "      <td>2.346217</td>\n",
       "      <td>...</td>\n",
       "      <td>166.771744</td>\n",
       "      <td>399.105408</td>\n",
       "      <td>153.683090</td>\n",
       "      <td>80.086365</td>\n",
       "      <td>64.642540</td>\n",
       "      <td>86.513268</td>\n",
       "      <td>123.233734</td>\n",
       "      <td>186.522812</td>\n",
       "      <td>107.269867</td>\n",
       "      <td>163.319839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.156643</td>\n",
       "      <td>4.917971</td>\n",
       "      <td>6.914794</td>\n",
       "      <td>6.584577</td>\n",
       "      <td>1.623989</td>\n",
       "      <td>5.219904</td>\n",
       "      <td>7.672572</td>\n",
       "      <td>9.140758</td>\n",
       "      <td>5.750987</td>\n",
       "      <td>2.627729</td>\n",
       "      <td>...</td>\n",
       "      <td>199.748566</td>\n",
       "      <td>297.561798</td>\n",
       "      <td>149.803162</td>\n",
       "      <td>84.879875</td>\n",
       "      <td>66.953796</td>\n",
       "      <td>90.916534</td>\n",
       "      <td>126.755249</td>\n",
       "      <td>181.390167</td>\n",
       "      <td>112.286552</td>\n",
       "      <td>166.973053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.436962</td>\n",
       "      <td>1.301774</td>\n",
       "      <td>6.793815</td>\n",
       "      <td>3.620672</td>\n",
       "      <td>1.269546</td>\n",
       "      <td>2.655743</td>\n",
       "      <td>5.243719</td>\n",
       "      <td>6.758463</td>\n",
       "      <td>4.352636</td>\n",
       "      <td>1.941540</td>\n",
       "      <td>...</td>\n",
       "      <td>75.045914</td>\n",
       "      <td>171.823349</td>\n",
       "      <td>111.750275</td>\n",
       "      <td>62.643578</td>\n",
       "      <td>57.428719</td>\n",
       "      <td>72.822304</td>\n",
       "      <td>106.469200</td>\n",
       "      <td>154.672363</td>\n",
       "      <td>95.603989</td>\n",
       "      <td>150.293564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   quantile                                                              \\\n",
       "        FP1       FPz       FP2        F7        F3        Fz        F4   \n",
       "0  3.275757  3.171221  6.266855  3.505204  1.761071  3.587153  6.038462   \n",
       "1  3.482556  4.307556  6.733288  3.605462  2.020469  3.719703  6.900743   \n",
       "2  6.936589  8.235714  7.147687  6.368727  2.023022  5.579708  8.134004   \n",
       "3  5.156643  4.917971  6.914794  6.584577  1.623989  5.219904  7.672572   \n",
       "4  1.436962  1.301774  6.793815  3.620672  1.269546  2.655743  5.243719   \n",
       "\n",
       "                                 ...    variance                          \\\n",
       "         F8       FT9       FC5  ...         CP2         CP6        TP10   \n",
       "0  6.392021  4.244585  1.845967  ...   68.961700  129.270645  116.701103   \n",
       "1  6.842275  4.416522  1.803723  ...   86.855766  151.384186  133.853088   \n",
       "2  9.014104  5.933595  2.346217  ...  166.771744  399.105408  153.683090   \n",
       "3  9.140758  5.750987  2.627729  ...  199.748566  297.561798  149.803162   \n",
       "4  6.758463  4.352636  1.941540  ...   75.045914  171.823349  111.750275   \n",
       "\n",
       "                                                                        \\\n",
       "          P7         P3         Pz          P4          P8          O1   \n",
       "0  68.938408  61.535503  71.211472   90.592781  152.309875   97.097801   \n",
       "1  77.523170  70.528954  84.750725  108.770752  167.561554  114.627052   \n",
       "2  80.086365  64.642540  86.513268  123.233734  186.522812  107.269867   \n",
       "3  84.879875  66.953796  90.916534  126.755249  181.390167  112.286552   \n",
       "4  62.643578  57.428719  72.822304  106.469200  154.672363   95.603989   \n",
       "\n",
       "               \n",
       "           O2  \n",
       "0  130.508011  \n",
       "1  143.692932  \n",
       "2  163.319839  \n",
       "3  166.973053  \n",
       "4  150.293564  \n",
       "\n",
       "[5 rows x 192 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install xgboost\n",
    "# ! pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import sklearn \n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm version: 4.1.0\n",
      "xgboost version: 2.0.3\n",
      "catboost version: 1.2.2\n",
      "sklearn version: 1.2.2\n"
     ]
    }
   ],
   "source": [
    "print('lightgbm version:', lgb.__version__)\n",
    "print('xgboost version:', xgb.__version__)\n",
    "print('catboost version:', cb.__version__)\n",
    "print('sklearn version:', sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm = LGBMClassifier()\n",
    "xgboost = XGBRFClassifier()\n",
    "catboost = CatBoostClassifier()\n",
    "histgb = HistGradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classifier_dict = {\n",
    "    \"histgb\": histgb,\n",
    "    \"lgbm\": lightgbm,\n",
    "    \"catb\": catboost,\n",
    "    \"xgb\": xgboost\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    make_scorer,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    log_loss,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    ")\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate our models\n",
    "def evaluate_model(model_dict, X_train, y_train):\n",
    "    scoring = {\n",
    "        \"accuracy\": make_scorer(accuracy_score),\n",
    "        \"f1\": make_scorer(f1_score, average=\"macro\"),\n",
    "        \"precision\": make_scorer(precision_score, average=\"macro\"),\n",
    "        \"recall\": make_scorer(recall_score, average=\"macro\"),\n",
    "        \"roc_auc\": make_scorer(roc_auc_score, needs_proba=True),\n",
    "        \"log_loss\": make_scorer(log_loss, needs_proba=True),\n",
    "        \"mae\": make_scorer(mean_absolute_error),\n",
    "        \"r2\": make_scorer(r2_score),\n",
    "    }\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=3)\n",
    "\n",
    "    scores_dict = dict()\n",
    "    for name, model in model_dict.items():\n",
    "        # proba = cross_val_predict(model, X_train, y_train, cv=kf, method='predict_proba')\n",
    "        scores = cross_validate(\n",
    "            model, X_train, y_train, cv=kf, scoring=scoring, n_jobs=12, verbose=1\n",
    "        )\n",
    "        print(\"Model: \", name, \"done.\")\n",
    "        scores_dict[name] = scores\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   3 out of   3 | elapsed:   13.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  histgb done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   3 | elapsed:    6.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  lgbm done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   3 | elapsed:  1.3min finished\n",
      "c:\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "2 fits failed out of a total of 3.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Python38\\lib\\site-packages\\catboost\\core.py\", line 5100, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"c:\\Python38\\lib\\site-packages\\catboost\\core.py\", line 2319, in _fit\n",
      "    self._train(\n",
      "  File \"c:\\Python38\\lib\\site-packages\\catboost\\core.py\", line 1723, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4645, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4694, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: C:/Go_Agent/pipelines/BuildMaster/catboost.git/catboost/libs/train_lib/dir_helper.cpp:20: Can't create train working dir: catboost_info\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  catb done.\n",
      "Model:  xgb done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done   3 out of   3 | elapsed:    9.1s finished\n"
     ]
    }
   ],
   "source": [
    "scores_dict = evaluate_model(\n",
    "    model_classifier_dict, X_data.values.copy(), y_data.values.copy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'histgb': {'fit_time': array([11.19313049, 11.28312421, 11.44813275]),\n",
       "  'score_time': array([0.09700131, 0.04199553, 0.03398991]),\n",
       "  'test_accuracy': array([0.32423208, 0.31399317, 0.36986301]),\n",
       "  'test_f1': array([0.24016168, 0.16345679, 0.21460047]),\n",
       "  'test_precision': array([0.29677318, 0.14638298, 0.18870656]),\n",
       "  'test_recall': array([0.27230496, 0.18705882, 0.26475556]),\n",
       "  'test_roc_auc': array([nan, nan, nan]),\n",
       "  'test_log_loss': array([3.03297712, 3.32227322, 2.82979084]),\n",
       "  'test_mae': array([1.06825939, 1.15017065, 0.96232877]),\n",
       "  'test_r2': array([-0.61913866, -0.9368354 , -0.45077034])},\n",
       " 'lgbm': {'fit_time': array([3.79699373, 3.78799081, 3.68499851]),\n",
       "  'score_time': array([0.01599097, 0.01699162, 0.06298995]),\n",
       "  'test_accuracy': array([0.32081911, 0.31399317, 0.38356164]),\n",
       "  'test_f1': array([0.23313276, 0.17864747, 0.22242809]),\n",
       "  'test_precision': array([0.26461664, 0.18157333, 0.19364224]),\n",
       "  'test_recall': array([0.27229044, 0.19584436, 0.27518879]),\n",
       "  'test_roc_auc': array([nan, nan, nan]),\n",
       "  'test_log_loss': array([2.63564998, 2.70262741, 2.24086275]),\n",
       "  'test_mae': array([1.07849829, 1.14334471, 0.96917808]),\n",
       "  'test_r2': array([-0.6497936 , -0.90896726, -0.52261801])},\n",
       " 'catb': {'fit_time': array([ 0.10099673,  0.10099673, 75.68765092]),\n",
       "  'score_time': array([0.        , 0.        , 0.04298925]),\n",
       "  'test_accuracy': array([       nan,        nan, 0.35273973]),\n",
       "  'test_f1': array([       nan,        nan, 0.20519171]),\n",
       "  'test_precision': array([       nan,        nan, 0.18105102]),\n",
       "  'test_recall': array([       nan,        nan, 0.25864467]),\n",
       "  'test_roc_auc': array([nan, nan, nan]),\n",
       "  'test_log_loss': array([       nan,        nan, 1.57596677]),\n",
       "  'test_mae': array([       nan,        nan, 0.97945205]),\n",
       "  'test_r2': array([        nan,         nan, -0.47011394])},\n",
       " 'xgb': {'fit_time': array([7.17830086, 7.82830477, 8.05827904]),\n",
       "  'score_time': array([0.02599525, 0.01998854, 0.01700568]),\n",
       "  'test_accuracy': array([0.32081911, 0.41296928, 0.40410959]),\n",
       "  'test_f1': array([0.18109788, 0.18745059, 0.22728265]),\n",
       "  'test_precision': array([0.269998  , 0.18208106, 0.19550439]),\n",
       "  'test_recall': array([0.24855392, 0.23670168, 0.27389706]),\n",
       "  'test_roc_auc': array([nan, nan, nan]),\n",
       "  'test_log_loss': array([1.54781179, 1.32752069, 1.28999596]),\n",
       "  'test_mae': array([1.10238908, 0.98293515, 0.94520548]),\n",
       "  'test_r2': array([-0.7306112 , -0.65536723, -0.49774766])}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_nested_dict(nested_dict):\n",
    "    switched_dict = {}\n",
    "\n",
    "    for key1, dict2 in nested_dict.items():\n",
    "        for key2, data in dict2.items():\n",
    "            if key2 not in switched_dict:\n",
    "                switched_dict[key2] = {}\n",
    "            switched_dict[key2][key1] = data\n",
    "\n",
    "    return switched_dict\n",
    "scores_dict_switched = switch_nested_dict(scores_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time #1: catb with score of 75.68765091896057\n",
      "score_time #1: lgbm with score of 0.06298995018005371\n",
      "test_accuracy #1: xgb with score of 0.4041095890410959\n",
      "test_f1 #1: xgb with score of 0.22728264884650257\n",
      "test_precision #1: xgb with score of 0.19550438596491226\n",
      "test_recall #1: lgbm with score of 0.2751887917329094\n",
      "test_roc_auc #1: histgb with score of nan\n",
      "test_log_loss #1: histgb with score of 2.8297908350187053\n",
      "test_mae #1: catb with score of 0.9794520547945206\n",
      "test_r2 #1: histgb with score of -0.45077033728281046\n",
      "\n",
      "fit_time #2: histgb with score of 11.448132753372192\n",
      "score_time #2: catb with score of 0.042989253997802734\n",
      "test_accuracy #2: lgbm with score of 0.3835616438356164\n",
      "test_f1 #2: lgbm with score of 0.22242809102484573\n",
      "test_precision #2: lgbm with score of 0.19364224137931035\n",
      "test_recall #2: xgb with score of 0.27389705882352944\n",
      "test_roc_auc #2: lgbm with score of nan\n",
      "test_log_loss #2: lgbm with score of 2.240862751090143\n",
      "test_mae #2: lgbm with score of 0.9691780821917808\n",
      "test_r2 #2: catb with score of -0.4701139417799145\n",
      "\n",
      "fit_time #3: xgb with score of 8.058279037475586\n",
      "score_time #3: histgb with score of 0.033989906311035156\n",
      "test_accuracy #3: histgb with score of 0.3698630136986301\n",
      "test_f1 #3: histgb with score of 0.21460047003525265\n",
      "test_precision #3: histgb with score of 0.1887065637065637\n",
      "test_recall #3: histgb with score of 0.2647555643879173\n",
      "test_roc_auc #3: catb with score of nan\n",
      "test_log_loss #3: catb with score of 1.5759667708547385\n",
      "test_mae #3: histgb with score of 0.9623287671232876\n",
      "test_r2 #3: xgb with score of -0.4977476624900634\n",
      "\n",
      "fit_time #4: lgbm with score of 3.6849985122680664\n",
      "score_time #4: xgb with score of 0.01700568199157715\n",
      "test_accuracy #4: catb with score of 0.3527397260273973\n",
      "test_f1 #4: catb with score of 0.20519171384457024\n",
      "test_precision #4: catb with score of 0.18105101649405447\n",
      "test_recall #4: catb with score of 0.25864467408585057\n",
      "test_roc_auc #4: xgb with score of nan\n",
      "test_log_loss #4: xgb with score of 1.2899959605736655\n",
      "test_mae #4: xgb with score of 0.9452054794520548\n",
      "test_r2 #4: lgbm with score of -0.5226180111291971\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for rank in range(len(model_classifier_dict)):\n",
    "    for title, scores in scores_dict_switched.items():\n",
    "        tupl = sorted(scores.items(), key=lambda item: -item[1][2])[rank]\n",
    "        print(f\"{title} #{rank+1}:\", tupl[0], \"with score of\", tupl[1][2])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
